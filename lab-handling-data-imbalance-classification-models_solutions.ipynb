{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eb3032",
   "metadata": {},
   "source": [
    "## Lab | Handling Data Imbalance in Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1c051",
   "metadata": {},
   "source": [
    "**Scenario**\n",
    "\n",
    "You are working as an analyst with this internet service provider. You are provided with this historical data about your company's customers and their churn trends. Your task is to build a machine learning model that will help the company identify customers that are more likely to default/churn and thus prevent losses from such customers.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "In this lab, we will first take a look at the degree of imbalance in the data and correct it using the techniques we learned on the class.\n",
    "\n",
    "Here is the list of steps to be followed (building a simple model without balancing the data):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c2069",
   "metadata": {},
   "source": [
    " - **Import the required libraries and modules that you would need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2dd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102bf26",
   "metadata": {},
   "source": [
    " - **Read that data into Python and call the dataframe churnData.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc293643",
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData= pd.read_csv('Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b71ee1",
   "metadata": {},
   "source": [
    " - **Check the datatypes of all the columns in the data. You would see that the column TotalCharges is object type. Convert this column into numeric type using pd.to_numeric function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97292f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   OnlineSecurity    7043 non-null   object \n",
      " 7   OnlineBackup      7043 non-null   object \n",
      " 8   DeviceProtection  7043 non-null   object \n",
      " 9   TechSupport       7043 non-null   object \n",
      " 10  StreamingTV       7043 non-null   object \n",
      " 11  StreamingMovies   7043 non-null   object \n",
      " 12  Contract          7043 non-null   object \n",
      " 13  MonthlyCharges    7043 non-null   float64\n",
      " 14  TotalCharges      7043 non-null   object \n",
      " 15  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(13)\n",
      "memory usage: 880.5+ KB\n"
     ]
    }
   ],
   "source": [
    "churnData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94faf17",
   "metadata": {},
   "source": [
    "**Converting Total Charges to numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ffee177",
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData['TotalCharges']= pd.to_numeric(churnData['TotalCharges'], errors = 'coerce' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54508e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   OnlineSecurity    7043 non-null   object \n",
      " 7   OnlineBackup      7043 non-null   object \n",
      " 8   DeviceProtection  7043 non-null   object \n",
      " 9   TechSupport       7043 non-null   object \n",
      " 10  StreamingTV       7043 non-null   object \n",
      " 11  StreamingMovies   7043 non-null   object \n",
      " 12  Contract          7043 non-null   object \n",
      " 13  MonthlyCharges    7043 non-null   float64\n",
      " 14  TotalCharges      7032 non-null   float64\n",
      " 15  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 880.5+ KB\n"
     ]
    }
   ],
   "source": [
    "churnData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6646d7b8",
   "metadata": {},
   "source": [
    " - **Check for null values in the dataframe. Replace the null values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bd2b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ccff70",
   "metadata": {},
   "source": [
    " - TotalCharges column has 11 null values.\n",
    " - Dropping 11 nulls would not affect the data as it has 7043 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c10e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData.dropna(subset=['TotalCharges'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf91c514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630efcdb",
   "metadata": {},
   "source": [
    " - **Use the following features: tenure, SeniorCitizen, MonthlyCharges and TotalCharges :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d6b90",
   "metadata": {},
   "source": [
    "1. Scale the features either by using normalizer or a standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b84f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['tenure', 'SeniorCitizen', 'MonthlyCharges', 'TotalCharges'] \n",
    "X= churnData[features]\n",
    "y= churnData['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659950f",
   "metadata": {},
   "source": [
    " - Using MinMax scaler to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128875af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()\n",
    "X_scaled= scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede74f1c",
   "metadata": {},
   "source": [
    "2. Split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886326a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb17b3",
   "metadata": {},
   "source": [
    "3. Fit a logistic regression model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b1c63c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1990db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking predictions\n",
    "predictions= lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd0a019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'Yes', ..., 'No', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b40b53",
   "metadata": {},
   "source": [
    "4. Check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e6672f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35ae8c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803837953091685"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b70d3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.91      0.86      1033\n",
      "         Yes       0.63      0.43      0.51       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.72      0.67      0.69      1407\n",
      "weighted avg       0.76      0.78      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c97efb",
   "metadata": {},
   "source": [
    " - **Managing imbalance in the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925f4df",
   "metadata": {},
   "source": [
    "1. Check for the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb09b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5163\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60135470",
   "metadata": {},
   "source": [
    " - There is a huge imbalance in the representation of target values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf18d88",
   "metadata": {},
   "source": [
    "2. Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "3. Each time fit the model and see how the accuracy of the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dc3d79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5163\n",
       "Yes    5163\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying imblearn.over_sampling.SMOTE to the dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a87982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7346675274370562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.3, random_state=100)\n",
    "classification = LogisticRegression(random_state=100, multi_class='ovr').fit(X_train, y_train)\n",
    "s_predictions = classification.predict(X_test)\n",
    "\n",
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade45692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.74      0.72      0.73      1531\n",
      "         Yes       0.73      0.75      0.74      1567\n",
      "\n",
      "    accuracy                           0.73      3098\n",
      "   macro avg       0.73      0.73      0.73      3098\n",
      "weighted avg       0.73      0.73      0.73      3098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, s_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0439bbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     4610\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying imblearn.under_sampling.TomekLinks to the dataset.\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "X_tl, y_tl = tl.fit_resample(X, y)\n",
    "y_tl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e931230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     4443\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tl2, y_tl2 = tl.fit_resample(X_tl, y_tl)\n",
    "y_tl2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d453b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7911522633744856"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tl, y_tl, test_size=0.3, random_state=100)\n",
    "classification = LogisticRegression(random_state=100, multi_class='ovr').fit(X_train, y_train)\n",
    "t_predictions = classification.predict(X_test)\n",
    "\n",
    "classification.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e22763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.90      0.86      1355\n",
      "         Yes       0.70      0.55      0.61       589\n",
      "\n",
      "    accuracy                           0.79      1944\n",
      "   macro avg       0.76      0.72      0.74      1944\n",
      "weighted avg       0.78      0.79      0.78      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, t_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
